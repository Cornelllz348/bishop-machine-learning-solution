\pb{1.1}
We use a slightly better notation to write this problem. Let $X$
be the matrix of the form 
\[
X=\begin{bmatrix}x_{1}^{0} & x_{1}^{1} & \cdots & x_{1}^{M}\\
x_{2}^{0} & x_{2}^{1} & \cdots & x_{2}^{M}\\
\vdots & \vdots & \ddots & \vdots\\
x_{N}^{0} & x_{N}^{1} & \cdots & x_{N}^{M}
\end{bmatrix},\ \ t=\begin{bmatrix}t_{1}\\
t_{2}\\
\vdots\\
t_{n}
\end{bmatrix}
\]
The the problem can be rewritten in the following form: 
\begin{align*}
E(w) & =\frac{1}{2}\left(\left(Xw-t\right)^{T}\left(Xw-t\right)\right).
\end{align*}
Now we differentiate w.r.t $w$, note that 
\begin{align*}
E(w+h) & =\frac{1}{2}\left(X\left(w+h\right)-t\right)^{T}\left(X\left(w+h\right)-t\right)\\
 & =\frac{1}{2}\left(\left(Xw-t\right)^{T}+\left(Xh\right)^{T}\right)\left(Xw-t+Xh\right)\\
 & =\frac{1}{2}\left[\left(Xw-t\right)^{T}\left(Xw-t\right)+\left(Xw-t\right)^{T}Xh+\left(Xh\right)^{T}\left(Xw-t\right)+\left(Xh\right)^{T}\left(Xh\right)\right]\\
 & =E\left(w\right)+\left\langle \left(Xw-t\right)^{T},Xh\right\rangle +\frac{1}{2}\left\langle Xh,Xh\right\rangle \\
 & =E\left(w\right)+\left\langle X^{T}\left(Xw-t\right),h\right\rangle +\frac{1}{2}\left\langle Xh,Xh\right\rangle .
\end{align*}
Note that $\left\langle X^{T}\left(Xw-t\right),h\right\rangle \in\text{Hom}(\mathbb{R}^{M+1},\mathbb{R})$
and 
\[
\frac{1}{2}\left\langle Xh,Xh\right\rangle \leq\frac{1}{2}\left\Vert Xh\right\Vert \left\Vert Xh\right\Vert \leq\frac{C}{2}\left\Vert X\right\Vert _{\infty}^{2}\left\Vert h\right\Vert \xrightarrow{\left\Vert h\right\Vert \rightarrow0}0,
\]
it follows that $\nabla E(w)=X^{T}(Xw-t).$ Set it to zero and we
get 
\[
X^{T}(Xw-t)=0\iff X^{T}Xw=X^{\top}t.
\]
So $X^{T}X$ is the $A$ proposed in the problem. 
\[
\left[X^{T}X\right]_{ij}=\sum_{n=1}^{N}\left(x_{n}^{i}x_{n}^{j}\right)=\sum_{n=1}^{N}x_{n}^{i+j},\text{ and }\left[X^{T}t\right]_{i}=\sum_{n=1}^{N}x_{n}^{i}t_{n},
\]
as desired. 
